{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01e5bd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from methods import *\n",
    "import os, shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4470c4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#user inputs\n",
    "\n",
    "#load hyperparameters\n",
    "sizes = ['1_tiny', '2_small', '3_standard', '4_full']\n",
    "size_folders = ['naug_sized_f1/' + size for size in sizes]\n",
    "\n",
    "#datasets\n",
    "datasets = ['sst2']\n",
    "\n",
    "#number of output classes\n",
    "num_classes_list = [2, 2, 2, 6, 2]\n",
    "\n",
    "#number of augmentations per original sentence\n",
    "n_aug_list_dict = {'size_data_f1/1_tiny': [32, 32, 32, 32, 32], \n",
    "\t\t\t\t\t'size_data_f1/2_small': [32, 32, 32, 32, 32],\n",
    "\t\t\t\t\t'size_data_f1/3_standard': [16, 16, 16, 16, 4],\n",
    "\t\t\t\t\t'size_data_f1/4_full': [16, 16, 16, 16, 4]}\n",
    "\n",
    "if not os.path.isdir('size_data_f1'):\n",
    "    os.mkdir('size_data_f1')\n",
    "#number of words for input\n",
    "input_size_list = [50, 50, 40, 25, 25]\n",
    "\n",
    "alphas = [0.05, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "\n",
    "# Number of words for input\n",
    "input_size_list = [50,50,40,25,25]\n",
    "\n",
    "#word2vec dictionary\n",
    "huge_word2vec = 'word2vec/glove.840B.300d.txt'\n",
    "word2vec_len = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29ee6331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished weda for naug_sized_f1/1_tiny/sst2/train_orig.txt to naug_sized_f1/1_tiny/sst2/train_weda_naug_1.txt\n",
      "finished weda for naug_sized_f1/1_tiny/sst2/train_orig.txt to naug_sized_f1/1_tiny/sst2/train_weda_naug_2.txt\n",
      "finished weda for naug_sized_f1/1_tiny/sst2/train_orig.txt to naug_sized_f1/1_tiny/sst2/train_weda_naug_4.txt\n",
      "finished weda for naug_sized_f1/1_tiny/sst2/train_orig.txt to naug_sized_f1/1_tiny/sst2/train_weda_naug_8.txt\n",
      "finished weda for naug_sized_f1/1_tiny/sst2/train_orig.txt to naug_sized_f1/1_tiny/sst2/train_weda_naug_16.txt\n",
      "finished weda for naug_sized_f1/1_tiny/sst2/train_orig.txt to naug_sized_f1/1_tiny/sst2/train_weda_naug_32.txt\n",
      "finished weda for naug_sized_f1/2_small/sst2/train_orig.txt to naug_sized_f1/2_small/sst2/train_weda_naug_1.txt\n",
      "finished weda for naug_sized_f1/2_small/sst2/train_orig.txt to naug_sized_f1/2_small/sst2/train_weda_naug_2.txt\n",
      "finished weda for naug_sized_f1/2_small/sst2/train_orig.txt to naug_sized_f1/2_small/sst2/train_weda_naug_4.txt\n",
      "finished weda for naug_sized_f1/2_small/sst2/train_orig.txt to naug_sized_f1/2_small/sst2/train_weda_naug_8.txt\n",
      "finished weda for naug_sized_f1/2_small/sst2/train_orig.txt to naug_sized_f1/2_small/sst2/train_weda_naug_16.txt\n",
      "finished weda for naug_sized_f1/2_small/sst2/train_orig.txt to naug_sized_f1/2_small/sst2/train_weda_naug_32.txt\n",
      "finished weda for naug_sized_f1/3_standard/sst2/train_orig.txt to naug_sized_f1/3_standard/sst2/train_weda_naug_1.txt\n",
      "finished weda for naug_sized_f1/3_standard/sst2/train_orig.txt to naug_sized_f1/3_standard/sst2/train_weda_naug_2.txt\n",
      "finished weda for naug_sized_f1/3_standard/sst2/train_orig.txt to naug_sized_f1/3_standard/sst2/train_weda_naug_4.txt\n",
      "finished weda for naug_sized_f1/3_standard/sst2/train_orig.txt to naug_sized_f1/3_standard/sst2/train_weda_naug_8.txt\n",
      "finished weda for naug_sized_f1/3_standard/sst2/train_orig.txt to naug_sized_f1/3_standard/sst2/train_weda_naug_16.txt\n",
      "finished weda for naug_sized_f1/3_standard/sst2/train_orig.txt to naug_sized_f1/3_standard/sst2/train_weda_naug_32.txt\n",
      "finished weda for naug_sized_f1/4_full/sst2/train_orig.txt to naug_sized_f1/4_full/sst2/train_weda_naug_1.txt\n",
      "finished weda for naug_sized_f1/4_full/sst2/train_orig.txt to naug_sized_f1/4_full/sst2/train_weda_naug_2.txt\n",
      "finished weda for naug_sized_f1/4_full/sst2/train_orig.txt to naug_sized_f1/4_full/sst2/train_weda_naug_4.txt\n",
      "finished weda for naug_sized_f1/4_full/sst2/train_orig.txt to naug_sized_f1/4_full/sst2/train_weda_naug_8.txt\n",
      "finished weda for naug_sized_f1/4_full/sst2/train_orig.txt to naug_sized_f1/4_full/sst2/train_weda_naug_16.txt\n",
      "finished weda for naug_sized_f1/4_full/sst2/train_orig.txt to naug_sized_f1/4_full/sst2/train_weda_naug_32.txt\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.2 \n",
    "n_augs = [1,2,4,8,16,32]\n",
    "\n",
    "for size_folder in size_folders:\n",
    "    if not os.path.isdir(size_folder):\n",
    "        os.mkdir(size_folder)\n",
    "\n",
    "    dataset_folders = [size_folder + '/' + s for s in datasets]\n",
    "    #n_aug_list = n_aug_list_dict[size_folder]\n",
    "\n",
    "    #for each dataset\n",
    "    for i, dataset_folder in enumerate(dataset_folders):\n",
    "        if not os.path.isdir(dataset_folder):\n",
    "            os.mkdir(dataset_folder)\n",
    "\n",
    "        #n_aug = n_aug_list[i]\n",
    "\n",
    "        #pre-existing file locations\n",
    "        train_orig = dataset_folder + '/train_orig.txt'\n",
    "\n",
    "        for n_aug in n_augs:\n",
    "            output_file = dataset_folder + '/train_weda_naug_'+str(n_aug)+'.txt'\n",
    "\n",
    "            gen_standard_aug_weda(train_orig, output_file, n_aug)\n",
    "\n",
    "        #generate the vocab dictionary\n",
    "        #word2vec_pickle = dataset_folder + '/word2vec.p'\n",
    "        #gen_vocab_dicts(dataset_folder, word2vec_pickle, huge_word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11264f9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b7a3c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bde8f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AM205",
   "language": "python",
   "name": "am205"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
